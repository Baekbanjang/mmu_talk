import os
from dotenv import load_dotenv
import streamlit as st
import re
import google.generativeai as genai
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.prompts import PromptTemplate
from langchain_core.runnables import Runnable
from langchain.schema.output_parser import StrOutputParser
from langchain_core.documents.base import Document 

# === ì„¤ì • ===
load_dotenv()  # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
GOOGLE_API_KEY = st.secrets["google_api_key"]  # Streamlit ë¹„ë°€ ê´€ë¦¬ì—ì„œ Google API í‚¤ ê°€ì ¸ì˜¤ê¸°
genai.configure(api_key=GOOGLE_API_KEY)  # Google Generative AI ì„¤ì •

# ë°ì´í„° ë””ë ‰í† ë¦¬ ì„¤ì •
DATA_DIR = "data"  # ë°ì´í„° íŒŒì¼ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬

# ëª¨ë¸ ì„¤ì •
EMBEDDING_MODEL = "models/embedding-001"  # ì„ë² ë”© ëª¨ë¸
CHAT_MODEL = "gemini-1.5-flash"  # ì±„íŒ… ëª¨ë¸

# ì²­í¬ ì„¤ì •
CHUNK_SIZE = 800
CHUNK_OVERLAP = 300
TOP_K = 4

def get_text_files():
    """ë°ì´í„° ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  .txt íŒŒì¼ ì°¾ê¸°"""
    text_files = {}
    try:
        for file in os.listdir(DATA_DIR):
            if file.endswith('.txt'):
                # íŒŒì¼ ì´ë¦„ì—ì„œ í™•ì¥ì ì œê±°í•˜ì—¬ ì¹´í…Œê³ ë¦¬ë¡œ ì‚¬ìš©
                category = os.path.splitext(file)[0]
                text_files[category] = file
        return text_files
    except Exception as e:
        st.error(f"íŒŒì¼ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return {}

# === RAG ì²´ì¸ ê°œì„  ===
def get_enhanced_rag_chain():
    """ê°œì„ ëœ RAG ì²´ì¸ ìƒì„±"""
    template = """
    ë‹¤ìŒì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:

    ì»¨í…ìŠ¤íŠ¸: {context}

    ì§ˆë¬¸: {question}

    ë‹µë³€ ì‘ì„± ê·œì¹™:
    1. í•µì‹¬ ë‚´ìš©ì„ ë¨¼ì € 2-3ì¤„ë¡œ ìš”ì•½
    2. ìƒì„¸ ë‚´ìš©ì„ ë¶ˆë¦¿ í¬ì¸íŠ¸ë¡œ êµ¬ë¶„
    3. ì¤‘ìš” ë‚´ìš©ì€ **ê°•ì¡°** ì²˜ë¦¬
    4. ì°¸ê³  ì„¹ì…˜ ì‘ì„± ê·œì¹™:
       - ë‹´ë‹¹ë¶€ì„œê°€ ìˆìœ¼ë©´ "- ë‹´ë‹¹ë¶€ì„œ: [ë¶€ì„œëª…](â˜ xxx-xxxx)" í˜•ì‹ìœ¼ë¡œ ì²« ì¤„ì— í‘œì‹œ
       - URLì´ ìˆìœ¼ë©´ "* í•­ëª©ëª…: URL" í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
    5. ë¶ˆë¦¿ í¬ì¸íŠ¸ëŠ” ë¶™ì—¬ì„œ ì‹œì‘

    ë‹µë³€ í˜•ì‹:
    ğŸ“Œ í•µì‹¬ ìš”ì•½:
    (ê°„ë‹¨í•œ ìš”ì•½ ì œê³µ)

    ğŸ“‹ ìƒì„¸ ë‚´ìš©:
    â€¢**ì¤‘ìš” ë‚´ìš© 1**
    â€¢**ì¤‘ìš” ë‚´ìš© 2**
    â€¢ìƒì„¸ ë‚´ìš© 3
    (ê° í•­ëª©ì„ ìƒˆë¡œìš´ ì¤„ì— ì‹œì‘)

    ğŸ“š ì°¸ê³ :
    (ë‹´ë‹¹ë¶€ì„œ ì •ë³´ê°€ ìˆëŠ” ê²½ìš° í‘œì‹œ)
    (URL ì •ë³´ê°€ ìˆëŠ” ê²½ìš° í‘œì‹œ)
    """
    
    prompt = PromptTemplate.from_template(template)
    model = ChatGoogleGenerativeAI(
        model=CHAT_MODEL,
        temperature=0.3,
        google_api_key=GOOGLE_API_KEY
    )
    return prompt | model | StrOutputParser()

def process_multiple_text_files():
    """í…ìŠ¤íŠ¸ íŒŒì¼ë“¤ì„ ì²˜ë¦¬í•˜ì—¬ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ ìƒì„±"""
    all_documents = []
    text_files = get_text_files()
    
    try:
        if not text_files:
            raise Exception("í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        for category, filename in text_files.items():
            file_path = os.path.join(DATA_DIR, filename)
            if os.path.exists(file_path):
                with open(file_path, 'r', encoding='utf-8') as file:
                    text = file.read()
                
                # URL ì¶”ì¶œ (í…ìŠ¤íŠ¸ì—ì„œ URL íŒ¨í„´ ì°¾ê¸°)
                url_pattern = r'https?://[^\s]+'
                urls = re.findall(url_pattern, text)
                
                sections = [section.strip() for section in text.split('\n\n') if section.strip()]
                
                for i, section in enumerate(sections):
                    lines = section.split('\n')
                    title = lines[0] if lines else ""
                    content = '\n'.join(lines[1:]) if len(lines) > 1 else section
                    
                    # ë©”íƒ€ë°ì´í„°ì— URL í¬í•¨
                    doc = Document(
                        page_content=content,
                        metadata={
                            'source': file_path,
                            'category': category,
                            'section': i + 1,
                            'title': title,
                            'urls': urls  # URL ì •ë³´ ì¶”ê°€
                        }
                    )
                    all_documents.append(doc)
        
        if not all_documents:
            raise Exception("ì²˜ë¦¬í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            
        # ê°œì„ ëœ í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì •
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=CHUNK_SIZE,
            chunk_overlap=CHUNK_OVERLAP,
            separators=[
                "\n\n",  # í° ë‹¨ë½ êµ¬ë¶„
                "\n1. ", "\n2. ", "\n3. ",  # ì£¼ìš” í•­ëª© êµ¬ë¶„
                "\nê°€. ", "\në‚˜. ", "\në‹¤. ", "\në¼. ",  # ì„¸ë¶€ í•­ëª© êµ¬ë¶„
                "\n", # ì¼ë°˜ ì¤„ë°”ê¿ˆ
                ". ",  # ë¬¸ì¥ êµ¬ë¶„
                ", ", # êµ¬ë¬¸ êµ¬ë¶„
                " "  # ë‹¨ì–´ êµ¬ë¶„
            ],
            length_function=len,
            is_separator_regex=False
        )
        
        chunked_documents = text_splitter.split_documents(all_documents)
        return chunked_documents
        
    except Exception as e:
        st.error(f"í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def create_vector_store(documents):
    """ë²¡í„° ì €ì¥ì†Œ ìƒì„±"""
    try:
        embeddings = GoogleGenerativeAIEmbeddings(
            model=EMBEDDING_MODEL,
            google_api_key=GOOGLE_API_KEY
        )
        vector_store = FAISS.from_documents(documents, embedding=embeddings)
        vector_store.save_local("faiss_index")
        return vector_store
    except Exception as e:
        st.error(f"ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def process_question(question: str, vector_store):
    """ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬ ë° ì‘ë‹µ ìƒì„±"""
    try:
        # ì´ì „ ì»¨í…ìŠ¤íŠ¸ ì €ì¥ì„ ìœ„í•œ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if 'last_department_info' not in st.session_state:
            st.session_state.last_department_info = None
            
        retriever = vector_store.as_retriever(search_kwargs={"k": TOP_K})
        docs = retriever.invoke(question)
        
        # URL ì •ë³´ ìˆ˜ì§‘
        urls = []
        department_info = None
        
        # í˜„ì¬ ë¬¸ì„œì—ì„œ ë‹´ë‹¹ë¶€ì„œ ì •ë³´ ì°¾ê¸°
        for doc in docs:
            if 'urls' in doc.metadata and doc.metadata['urls']:
                urls.extend(doc.metadata['urls'])
            
            # ë‹´ë‹¹ë¶€ì„œ ì •ë³´ ì°¾ê¸°
            content = doc.page_content
            dept_pattern = r'ë‹´ë‹¹ë¶€ì„œ[^\n]*?([^()]+\(â˜\s*\d{3}-\d{4}\))'
            dept_matches = re.findall(dept_pattern, content, re.DOTALL)
            
            if dept_matches:
                department_info = dept_matches[0].strip()
                st.session_state.last_department_info = department_info  # ì°¾ì€ ì •ë³´ ì €ì¥
                break
                
        # í˜„ì¬ ë¬¸ì„œì—ì„œ ì°¾ì§€ ëª»í–ˆë‹¤ë©´ ì´ì „ ì •ë³´ ì‚¬ìš©
        if not department_info and st.session_state.last_department_info:
            department_info = st.session_state.last_department_info
            
        urls = list(set(urls))  # ì¤‘ë³µ ì œê±°
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = "\n\n".join(doc.page_content for doc in docs)
        if department_info:
            context += f"\n\nDEPARTMENT_INFO: {department_info}"
        if urls:
            context += "\n\nURL_LIST: " + "\n".join(urls)
        
        chain = get_enhanced_rag_chain()
        response = chain.invoke({
            "question": question,
            "context": context
        })
        
        return response, docs
    except Exception as e:
        st.error(f"ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", None

def format_response(response: str) -> str:
    """ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ë³´ê¸° ì¢‹ê²Œ í¬ë§¤íŒ…"""
    formatted_sections = []
    
    # ì‘ë‹µì„ ì£¼ìš” ì„¹ì…˜ìœ¼ë¡œ ë¶„ë¦¬
    sections = response.split('\n')
    current_section = []
    
    for line in sections:
        line = line.strip()
        if not line:
            continue
            
        # ìƒˆë¡œìš´ ì„¹ì…˜ ì‹œì‘
        if any(line.startswith(marker) for marker in ['ğŸ“Œ', 'ğŸ“‹', 'ğŸ“š', 'ğŸ’¡']):
            if current_section:
                formatted_sections.append('\n'.join(current_section))
                current_section = []
            current_section.append(line)
            if not line.endswith(':\n\n'):  # ì„¹ì…˜ ì œëª©ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ë¹ˆ ì¤„ ì¶”ê°€
                current_section.append('')  # ì„¹ì…˜ ë‚´ìš©ê³¼ ì œëª© ì‚¬ì´ ë¹ˆ ì¤„ ì¶”ê°€
            continue
        
        # ë¶ˆë¦¿ í¬ì¸íŠ¸ ì²˜ë¦¬
        if line.startswith('â€¢'):
            # ì—¬ëŸ¬ ë¶ˆë¦¿ í¬ì¸íŠ¸ê°€ í•œ ì¤„ì— ìˆëŠ” ê²½ìš° ë¶„ë¦¬
            bullet_points = line.split('â€¢')[1:]  # ì²« ë²ˆì§¸ ë¹ˆ ë¬¸ìì—´ ì œê±°
            for point in bullet_points:
                if point.strip():
                    current_section.append(f"  â€¢ {point.strip()}")
                    current_section.append('')  # ê° ë¶ˆë¦¿ í¬ì¸íŠ¸ ë’¤ì— ë¹ˆ ì¤„ ì¶”ê°€
            continue
            
        current_section.append(line)
    
    # ë§ˆì§€ë§‰ ì„¹ì…˜ ì¶”ê°€
    if current_section:
        formatted_sections.append('\n'.join(current_section))
    
    # ìµœì¢… í…ìŠ¤íŠ¸ ì¡°í•©
    formatted_text = '\n\n'.join(formatted_sections)
    
    # ì¤‘ë³µë˜ëŠ” ë¹ˆ ì¤„ ì œê±° ë° ì •ë¦¬
    lines = formatted_text.split('\n')
    cleaned_lines = []
    prev_empty = False
    
    for line in lines:
        if line.strip():
            cleaned_lines.append(line)
            prev_empty = False
        elif not prev_empty:
            cleaned_lines.append(line)
            prev_empty = True
    
    return '\n'.join(cleaned_lines)

def main():
    # í˜ì´ì§€ ì„¤ì •
    st.set_page_config(page_title="ëŒ€í™”í˜• ê²€ìƒ‰ ì‹œìŠ¤í…œ", layout="wide")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    st.title("ëª©í¬í•´ì–‘ëŒ€ìƒì„ ìœ„í•œ ì±—ë´‡ - ë®¤í†¡ğŸ¬")
    st.subheader("ğŸ«í•™êµ ìƒí™œì— ëŒ€í•œ ëª¨ë“  ê²ƒì„ ë¬¼ì–´ë³´ì„¸ìš”ğŸ”", divider='rainbow')
    
    # ë°ì´í„° ì´ˆê¸° ì²˜ë¦¬
    if 'vector_store' not in st.session_state:
        with st.spinner("ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            # ì²˜ë¦¬ëœ íŒŒì¼ ì •ë³´ í‘œì‹œ
            text_files = get_text_files()
            if text_files:
                st.info(f"ë°œê²¬ëœ ë°ì´í„° íŒŒì¼: {', '.join(text_files.keys())}")
                
                chunks = process_multiple_text_files()
                if chunks:
                    st.session_state.vector_store = create_vector_store(chunks)
                    st.success(f"ì´ {len(text_files)} ê°œì˜ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!")
                else:
                    st.error("ë°ì´í„° ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    st.stop()
            else:
                st.error(f"'{DATA_DIR}' ê²½ë¡œì—ì„œ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.stop()

    # ì‚¬ì´ë“œë°”ì— ëŒ€í™” ë‚´ì—­ ì§€ìš°ê¸° ë²„íŠ¼
    with st.sidebar:
        st.title("ì„¤ì •")
        if st.button('ëŒ€í™” ë‚´ì—­ ì§€ìš°ê¸°'):
            st.session_state.chat_history = []
            st.rerun()

    # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    if not st.session_state.chat_history:
        st.session_state.chat_history.append({
            "role": "assistant",
            "content": "ì°¾ìœ¼ì‹œëŠ” ì •ë³´ë¥¼ ë®¤í†¡ğŸ¬ì—ê²Œ ë‚¨ê²¨ì£¼ì„¸ìš”!"
        })

    # ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
    for message in st.session_state.chat_history:
        with st.chat_message(message["role"]):
            st.markdown(format_response(message["content"]))

    # ìƒˆë¡œìš´ ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        
        # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ìƒì„±
        with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            response, docs = process_question(prompt, st.session_state.vector_store)
            formatted_response = format_response(response)
            
            # ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
            st.session_state.chat_history.append({
                "role": "assistant",
                "content": response
            })
            
            # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
            st.rerun()

if __name__ == "__main__":
    main()